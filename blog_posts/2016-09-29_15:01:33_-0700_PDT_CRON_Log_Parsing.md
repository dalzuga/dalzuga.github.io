2016-09-29_15:01:33_-0700_PDT
# CRON_Log_Parsing [working title]

Recently, as part of our daily routine of preparing for SRE interview
questions, Guillaume started sending us a packet of exercises. One of
the exercises was particularly interesting to me. I liked this
question because it illustrates the importance of good thought process.

The exercise is as follows:

```
By using this cron log:
https://s3.amazonaws.com/holbertonintranet/files/sandbox/cron

Provide the list of all cron commands with the delay ("The cron task
'Holberton' is executed each 50 seconds")
```
Good thought process, in my opinion, is being aware of the assumptions
you are making when interpreting a problem, if any. In an interview
setting, these assumptions generate clarifying questions.

This problem jumped out at me because the first assumption I made was
pretty ugly. As part of my strategy to make sure I don't overlook any
special cases (and also for maximizing the learning I get from each
problem), I like to imagine the worst of a problem before breaking it
down into smaller chunks (or looking inside the log itself, in this
case.)  So, I pretended that this is a very complex server for a
ficticious developer team, with thousands of jobs being run by CRON
and many unique commands. No one individual really knows what this
server does, but everyone relies on it to run their command at a set
frequency.

Just by thinking of this, it occurred to me that this problem must not
have a solution. Or, at least, not a unique solution.

## The Clarifying Question

The clarifying question that jumped at me was as follows: "Can I
assume that each command is run by exactly one CRON job?"

In other words, are there two people on the team that are unknowingly
running the same command, perhaps with different delays?

Since Guillaume is not generally in the habit of asking trick
questions (like Julien is) I found it safe to assume, at this point,
that we are not expected to handle this complication. But I'm happy to
have thought of it because I'll be aware of this limitation.

```
Assumption: each unique command is run by one and only one CRON job.
```

The structure of the problem is clearer, and our task is simplified.

## Parsing the file

The lines on the log file look like this:

`Sep 21 17:30:01 ip-172-31-27-229 CROND[process ID]: (root) CMD some_command`

Using python's regular expressions module, I parsed the file with the following search:

```
regexp = "CROND\[[0-9]*\]: \(root\) CMD (.*)"
s = re.search(regexp, line)
```

You can see that I am capturing the command with `(.*)` and access it
with `s.group(1)`.

## How Many Commands

I first decided to count how many unique CRON commands there are in
this particular log file. Also, I decided to count how many CRON
commands there are in total just in case I need to make a sanity check
later on.

This was the result:

```
uniqueCmdCount: 10
count by CROND: 1999
```

I now know I have 10 unique commands in total, for a total of 10 CRON
jobs.

## The Lazy Solution

I knew, at first, that I could get the first two times a specific
command has run, and subtract the difference to get the delay.  But
this discards the rest of the information in the log, and doesn't take
into account variations in the run times. This would be a lazy solution.

## The Almost Correct Solution

This particular log spans a few days of activity. For my solution, I
decided to count how many times the command had run, and then divide
by the stretch of time between the first and last times this command
ran. This was much better than the lazy solution, since any
approximations would be averaged out and it was not needlessly complicated.

Here are some of the results:

```
command: (su -s /bin/bash -c 'if [[ ! -z ${HOLBERTON_INTRANET_AUTO_CORRECTI...)
count: 1042
first timestamp: 1900-09-18 03:10:01
last timestamp: 1900-09-21 17:55:01
difference: 3 days, 14:45:00
delay: 0:04:59.712092
```

Nice! Or so I thought... At this point I thought I was handling some
variation which was due to CRON.

Another result:

```
command: (su -s /bin/bash -c 'source /opt/elasticbeanstalk/support/envvars ...
count: 86
first timestamp: 1900-09-18 04:05:01
last timestamp: 1900-09-21 17:05:01
difference: 3 days, 13:00:00
delay: 0:59:18.139534
```

Umm... I guess this one is one hour? ...

Upon examining the log to confirm my result, it appears that CRON was
more accurate that my results seemed to indicate.


## P.S.: Parsing the datetimes

For the sake of completeness, here is how I parsed the times. To get the
time string I simply took the first 15 characters of each line via the
Python slice (`[:15]`)

I used the `datetime` module of Python 2.7 to interpret the times
(using `strptime()` function which allows you to specify the date
format).

I appended all of these timestamps to a list for each command.